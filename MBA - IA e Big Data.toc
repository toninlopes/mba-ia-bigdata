\changetocdepth {4}
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\setlength {\cftchapterindent }{\cftlastnumwidth } \setlength {\cftchapternumwidth }{2em}
\contentsline {part}{\partnumberline {I}\MakeTextUppercase []{Curso 2 - Ciência de Dados, Aprendizado de Máquina e Mineração de Dados}}{5}{part.1}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {1}\MakeTextUppercase []{Naive Bayes}}{7}{chapter.1}%
\contentsline {section}{\numberline {1.1}Para que é utilizado?}{7}{section.1.1}%
\contentsline {section}{\numberline {1.2}A Base Teórica: O Teorema de Bayes}{7}{section.1.2}%
\contentsline {section}{\numberline {1.3}O "Naive" (Ingênuo) e a Fórmula para Múltiplas Características}{8}{section.1.3}%
\contentsline {section}{\numberline {1.4}Tipos de Naive Bayes}{8}{section.1.4}%
\contentsline {section}{\numberline {1.5}Exemplo Prático: Filtro de Spam}{9}{section.1.5}%
\contentsline {section}{\numberline {1.6}Exemplo em Python}{9}{section.1.6}%
\contentsline {section}{\numberline {1.7}Pontos Positivos (Vantagens)}{11}{section.1.7}%
\contentsline {section}{\numberline {1.8}Pontos Negativos (Desvantagens e Cuidados)}{11}{section.1.8}%
\contentsline {section}{\numberline {1.9}Conclusão}{12}{section.1.9}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {2}\MakeTextUppercase []{Árvore de Decisão}}{13}{chapter.2}%
\contentsline {section}{\numberline {2.1}Para que é utilizado?}{13}{section.2.1}%
\contentsline {section}{\numberline {2.2}O Conceito Central: Como a Árvore "Aprende"?}{13}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Entropia}{14}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Ganho de Informação}{14}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Índice Gini}{14}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Exemplo Prático: Jogar Tênis?}{15}{section.2.3}%
\contentsline {section}{\numberline {2.4}Exemplo em Python}{15}{section.2.4}%
\contentsline {section}{\numberline {2.5}Pontos Positivos (Vantages)}{16}{section.2.5}%
\contentsline {section}{\numberline {2.6}Pontos Negativos (Desvantagens)}{17}{section.2.6}%
\contentsline {section}{\numberline {2.7}Como Mitigar as Desvantagens no Contexto de Big Data?}{17}{section.2.7}%
\contentsline {section}{\numberline {2.8}Conclusão}{17}{section.2.8}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {3}\MakeTextUppercase []{Avaliação de Classificadores}}{19}{chapter.3}%
\contentsline {section}{\numberline {3.1}Para que é utilizado?}{19}{section.3.1}%
\contentsline {section}{\numberline {3.2}Conceitos e Métricas Fundamentasi (Com Fórmulas)}{19}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Matriz de Confusão (Confusion Matrix)}{20}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Acurácia (Accuracy)}{20}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Precisão (Precision)}{20}{subsection.3.2.3}%
\contentsline {subsection}{\numberline {3.2.4}Revocação (Recall ou Sensibilidade)}{21}{subsection.3.2.4}%
\contentsline {subsection}{\numberline {3.2.5}Pontuação F1 (F1-Score)}{21}{subsection.3.2.5}%
\contentsline {subsection}{\numberline {3.2.6}Curva ROC e AUC (Área Sob a Curva)}{21}{subsection.3.2.6}%
\contentsline {section}{\numberline {3.3}Exemplo Prático}{22}{section.3.3}%
\contentsline {section}{\numberline {3.4}Exemplo em Python}{22}{section.3.4}%
\contentsline {section}{\numberline {3.5}Pontos Positivos (Por que é crucial?)}{24}{section.3.5}%
\contentsline {section}{\numberline {3.6}Pontos Negativos (Cuidados)}{24}{section.3.6}%
\contentsline {section}{\numberline {3.7}Conclusão}{25}{section.3.7}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {4}\MakeTextUppercase []{Random Forest}}{27}{chapter.4}%
\contentsline {section}{\numberline {4.1}Para que é utilizado?}{27}{section.4.1}%
\contentsline {section}{\numberline {4.2}O Algoritmo: Como Funciona? (Conceito e Pseudocódigo)}{28}{section.4.2}%
\contentsline {section}{\numberline {4.3}Exemplo Prático: Prever se uma pessoa gosta de filme de ação}{29}{section.4.3}%
\contentsline {section}{\numberline {4.4}Exmplo em Python}{29}{section.4.4}%
\contentsline {section}{\numberline {4.5}Pontos Positivos (Vantagens)}{31}{section.4.5}%
\contentsline {section}{\numberline {4.6}Pontos Negativos (Desvantagens)}{31}{section.4.6}%
\contentsline {section}{\numberline {4.7}Conclusão}{32}{section.4.7}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {5}\MakeTextUppercase []{Support Vector Machine (SVM)}}{33}{chapter.5}%
\contentsline {section}{\numberline {5.1}Para que é utilizado?}{33}{section.5.1}%
\contentsline {section}{\numberline {5.2}Conceitos e Fórmulas Chave}{34}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}SVM Linear (Caso Separável)}{34}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Kernel Trick (O Truque do Kernel)}{34}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}SVM com Margem Suave (Soft Margin)}{35}{subsection.5.2.3}%
\contentsline {section}{\numberline {5.3}Exemplo Prático}{35}{section.5.3}%
\contentsline {section}{\numberline {5.4}Exemplo em Python}{35}{section.5.4}%
\contentsline {section}{\numberline {5.5}Pontos Positivos (Vantagens)}{37}{section.5.5}%
\contentsline {section}{\numberline {5.6}Pontos Negativos (Desvantagens)}{37}{section.5.6}%
\contentsline {section}{\numberline {5.7}Conclusão}{38}{section.5.7}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {6}\MakeTextUppercase []{K-Nearest Neighbors - KNN}}{39}{chapter.6}%
\contentsline {section}{\numberline {6.1}Para que é utilizado?}{39}{section.6.1}%
\contentsline {section}{\numberline {6.2}O Algoritmo: Como Funciona? (Conceitos e Passos)}{40}{section.6.2}%
\contentsline {section}{\numberline {6.3}A Fórmula Chave: Medida de Distância}{40}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Distância Euclidiana (a mais comum)}{40}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Distância de Manhattan (Distância do Quarteirão)}{40}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Distância de Minkowski}{41}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Distância de Hamming}{41}{subsection.6.3.4}%
\contentsline {section}{\numberline {6.4}Exemplo Prático: Classificação de um Novo Paciente}{41}{section.6.4}%
\contentsline {section}{\numberline {6.5}Exemplo em Python}{42}{section.6.5}%
\contentsline {section}{\numberline {6.6}Pontos Positivos (Vantagens)}{43}{section.6.6}%
\contentsline {section}{\numberline {6.7}Pontos Negativos (Desvantagens) - Críticos no Contexto de Big Data}{44}{section.6.7}%
\contentsline {section}{\numberline {6.8}Conclusão}{45}{section.6.8}%
