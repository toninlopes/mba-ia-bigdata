\chapter{Introdução a Estatística na Ciência da Computação Experimental}

A interseção entre Estatística, Ciência da Computação Experimental, Inteligência Artificial e Big Data é fascinante e fundamental. A estatística é, de fato, o alicerce sobre o qual o Machine Learning moderno é construído, fornecendo as ferramentas para quantificar a incerteza, validar modelos e extrair significado de grandes volumes de dados.

A parte de "Experimental" sugere um foco importante em \textbf{testes de hipóteses}, \textbf{design de experimentos (DoE)} e \textbf{análise de variância (ANOVA)}, que são cruciais para comparar algoritmos de ML ou validar o impacto de novas features (como em testes A/B).


\section{O Propósito da Estatística}

O propósito fundamental da Estatística é fornecer um conjunto de métodos rigorosos para responder a uma pergunta de interesse sobre um universo total, a População. O desafio central é que quase nunca temos acesso à população inteira (seja por custo, tempo ou inviabilidade prática).

Para resolver isso, o propósito da estatística se desdobra em um processo claro de duas etapas: Análise Descritiva e Análise Inferencial.

\subsection{Análise Descritiva (Descrever a Amostra)}

Primeiro, realizamos um Planejamento para coletar um subconjunto representativo da população, a \textbf{Amostra}.

O primeiro propósito da estatística é, então, simplesmente organizar, resumir e apresentar os dados desta amostra de forma compreensível. Isso é feito com:
\begin{itemize}
	\item Gráficos como os de pizza e barras.
	\item Tabelas.
	\item Cálculo de métricas-resumo como média, mediana, etc.
\end{itemize}


\subsection{Análise Inferencial ()Inferir sobre a População)}

Inferir sobre a \textbf{População} é o grande objetivo. Sendo assim, o segundo propósito da Estatística é usar os dados resumidos da amostra para tirar conclusões, fazer previsões e tomar decisões sobre a população inteira da qual a amostra foi retirada.

É aqui que todo o nosso estudo sobre Teoria de Probabilidades se torna vital. A inferência não é um "chute"; é um salto calculado. A probabilidade nos permite quantificar a incerteza desse salto (por exemplo, a "margem de erro" e o "nível de confiança").

Esse processo inferencial pode seguir duas grandes filosofias/abordagem: Clássica e Bayesiana.

Abordagem \textbf{Clássica (Frequentista)} é a abordagem que a maioria das pessoas aprende primeiro (focada em $p$-valores e Intervalos de Confiança). Nela, a probabilidade é vista como a \textbf{frequência de longo prazo} de um evento. O parâmetro que queremos descobrir (ex: a média $\mu$ da população) é considerado um valor \textbf{fixo, mas desconhecido}. A \textbf{incerteza} está na nossa \textbf{amostra} (que é aleatória). Um \textbf{Intervalo de Confiança de 95\%} significa que 95\% dos intervalos criados por este \textbf{método} capturariam o parâmetro verdadeiro se repetíssemos o experimento várias vezes.

Na abordagem \textbf{Bayesiana}, a probabilidade é definida como um \textbf{grau de crença} ou confiança sobre uma afirmação. O parâmetro (ex: $\mu$) não é visto como fixo; ele é uma \textbf{variável aleatória} sobre a qual temos incerteza. A inferência funciona atualizando nossas crenças:
\begin{itemize}
	\item Começamos com uma \textbf{crença prévia} (distribuição a priori).
	\item Coletamos dados (a \textit{likelihood}).
	\item Usamos o Teorema de Bayes para combinar os dois e obter uma \textbf{crença atualizada} (distribuição a posteriori). A inferência é esta distribuição posterior.
\end{itemize}

Portanto, em resumo, o propósito da Estatística não é apenas calcular números, mas sim usar uma pequena parte (amostra) para entender o todo (população), tudo isso fundamentado na lógica da probabilidade para gerenciar a incerteza.

\section{A Importância Crítica do Planejamento e Desenho do Estudo}

A forma como o estudo é planejado e os dados são coletados define a validade de qualquer análise subsequente. O ponto de partida de todo estudo estatístico é a \textbf{Pergunta de Interesse}.

A partir dessa pergunta, as etapas do estudo se dividem em duas grandes fases, que podemos estruturar da seguinte forma:

\begin{enumerate}
	\item \textbf{Planejamento:} Esta é a fundação do estudo, é a etapa mais crítica para garantir a validade dos resultados. O planejamento define:
	\begin{itemize}
		\item \textbf{Desenho do Estudo:} Como a pesquisa será arquitetada para responder à pergunta. É aqui que se decide se o estudo será \textbf{Observacional} (apenas observar) ou \textbf{Experimental} (interferir e medir o efeito).
		\item \textbf{Amostragem:} Como a amostra (o subconjunto) será selecionada da população. A decisão crucial é se será \textbf{probabilística} (aleatória, permitindo inferência) ou \textbf{não probabilística} (conveniência).
		\item \textbf{Coleta dos Dados:} A definição prática de \textbf{quem} (unidades amostrais), \textbf{o que} (as variáveis) e \textbf{quando} (transversal ou longitudinal) será avaliado.
	\end{itemize}
	
	\item \textbf{Análise dos Dados:} Somente após o planejamento e a coleta, passamos à análise, que também se divide em duas etapas:
	\begin{itemize}
		\item \textbf{Análise Descritiva:} É o processo de \textbf{arrumar a casa}. O objetivo é organizar, resumir e visualizar os dados da \textbf{amostra}. É nesta etapa que identificamos os \textbf{tipos de variáveis} (qualitativas/quantitativas) e calculamos medidas-resumo.
		\item \textbf{Análise Inferencial:} Este é o \textbf{grande salto} da estatística. É quando usamos os dados da amostra para tirar conclusões sobre a \textbf{população} inteira. Como vimos, este processo é inteiramente baseado na \textbf{Teoria de Probabilidades} e no estudo das distribuições.
	\end{itemize}
	
\end{enumerate}

\subsection{Desenhos de Estudo}

O \textbf{Desenho do Estudo} é o plano arquitetônico da pesquisa. É a decisão mais fundamental sobre \textbf{como} você coletará os dados para responder sua pergunta de interesse. Os desenhos de estudo se dividem em duas categorias principais, baseadas no nível de interferência do pesquisador: Estudos Experimentais; e Estudos Observacionais.

Nos \textbf{Estudos Experimentais}, o pesquisador \textbf{interfere ativamente} no processo, planejando e aplicando uma intervenção. O \textbf{objetivo} é estabelecer uma relação de \textbf{causa e efeito} que permite um \textbf{maior controle} sobre fatores externos que podem influenciar o resultado.

Exemplos Clássicos:
\begin{itemize}
	\item \textbf{Testes Clínicos (\textit{Clinical Trials}):} Como os usados para testar a eficácia das vacinas da COVID-19 (BNT162b2), onde um grupo recebe a vacina e outro recebe um placebo.
	\item \textbf{Testes A/B:} Muito comuns em Ciência da Computação, onde se testa o impacto de uma mudança (ex: um novo layout de site) em um grupo de usuários comparado a um grupo de controle.
\end{itemize}

Nos \textbf{Estudos Observacionais} o pesquisador \textbf{não interfere} no processo; ele apenas observa, coleta e analisa os dados da realidade como ela é. O \textbf{objetivo} é encontrar \textbf{associações} ou \textbf{correlações} (o que é diferente de causalidade). São muitas vezes mais viáveis de realizar, mas possuem \textbf{menos controle} sobre variáveis de confusão.

Exemplos Clássicos:
\begin{itemize}
	\item \textbf{Estudos de Caso-Controle (\textit{Case-control}):} Compara um grupo que tem uma condição (ex: câncer de pulmão) com um grupo que não tem, e "olha para trás" para ver a exposição a fatores de risco (ex: tabagismo).
	\item \textbf{Estudos de Coorte (Cohort):} Acompanha um grupo de pessoas (expostas e não expostas a um fator) ao longo do tempo para ver quem desenvolve a doença. O \textit{British Doctors' Study}, que estabeleceu a ligação entre fumar e câncer de pulmão, foi um estudo de coorte prospectivo que durou 50 anos.
\end{itemize}

Os estudos também podem ser classificados pelo tempo:

\begin{itemize}
	\item \textbf{Transversais (Cross-sectional)}: Os dados são coletados em um único momento.
	
	\item \textbf{Longitudinais}: Os dados são coletados ao longo do tempo, permitindo acompanhar os indivíduos (ex: o estudo dos médicos britânicos, que durou 50 anos).
\end{itemize}


\subsection{Como selecionar (Amostragem) e o que medir (Variáveis)}

A \textbf{Amostragem} é o segundo pilar do planejamento, tão crucial quanto o Desenho do Estudo. Ela define \textbf{como} vamos selecionar as unidades de estudo (as "unidades amostrais") da população.

Podemos dividir os métodos de amostragem em duas categorias principais: Amostragem Probabilística; e Não Probabilística.

Na \textbf{Amostragem Probabilística (O Padrão-Ouro)},  cada unidade da população tem uma \textbf{probabilidade conhecida} (e maior que zero) de ser selecionada para a amostra. A seleção envolve um mecanismo aleatório. Este é o único tipo de amostragem que nos permite usar a \textbf{Análise Inferencial} para generalizar os resultados da amostra para a população com um nível de confiança conhecido.

Tipos de Amostragem Probabilística:
\begin{itemize}
	\item \textbf{Amostra Aleatória Simples:} É o método mais básico, onde cada unidade tem exatamente a mesma probabilidade de ser escolhida.
	\item \textbf{Planos Amostrais Sofisticados:} Incluem métodos como amostragem estratificada (dividindo a população em grupos), sistemática (selecionando a cada $k$-ésimo item) ou por conglomerados em múltiplos estágios.
\end{itemize}

Na \textbf{Amostragem Não Probabilística} a seleção é feita por critérios não aleatórios.

Exemplos:
\begin{itemize}
	\item \textbf{Amostragem por Conveniência:} Selecionar os voluntários mais fáceis de acessar.
	\item \textbf{Amostragem de Voluntários:} Quando os próprios indivíduos se oferecem para o estudo.
\end{itemize}

O método \textbf{Amostragem Não Probabilística} introduz um alto risco de \textbf{viés (bias)}, pois a amostra dificilmente será representativa da população. As conclusões tiradas de uma amostra não probabilística não podem ser generalizadas estatisticamente.


\subsection{Classificação de Variáveis (O "O quê" da Análise)}

Este é o último pilar do planejamento: definir \textbf{o quê} vamos medir. Podemos classificar as variáveis em duas categorias principais: Variáveis Qualitativas (ou Categóricas); Variáveis Quantitativas (ou Numéricas). 

\subsubsection{Variáveis Qualitativas (ou Categóricas)}

A principal característica dessas variáveis é que elas representam \textbf{categorias} ou \textbf{qualidades}. A distinção crucial entre seus dois subtipos é a presença ou ausência de uma ordem natural. As Variáveis Qualitativas se subdividem em dois grupos: \textbf{Variáveis Nominais}; e \textbf{Variáveis Ordinais}.\\

\textbf{Variáveis Nominais}

Variáveis Nominais são variáveis qualitativas cujas categorias \textbf{não possuem nenhuma ordem} ou hierarquia lógica entre si. Uma categoria não é "maior" ou "melhor" que a outra; são apenas diferentes.

Exemplos:
\begin{itemize}
	\item \textbf{Navegador Web:} Os valores possíveis (ex: "Chrome", "Firefox", "Safari", "Edge") são apenas nomes. Não há uma ordem matemática ou lógica entre eles.
	\item \textbf{Bandeira do Cartão:} Os valores (ex: "Visa", "Mastercard", "Amex") são categorias nominais que identificam a rede de pagamento.
	\item \textbf{Operadora de Telefonia:} "Vivo", "Claro", "Tim".
	\item \textbf{ Cidade de Origem:} "São Paulo", "Rio de Janeiro", "Belo Horizonte".
\end{itemize}

\textbf{Contexto em ML/Python/R:} Para usar variáveis nominais em modelos de machine learning (como regressão logística ou redes neurais), precisamos "traduzi-las" em números. A técnica mais comum é o \textbf{One-Hot Encoding} (ou \textbf{dummy variables}), onde criamos uma nova coluna binária (0 ou 1) para cada categoria.\\


\textbf{Variáveis Ordinais}

Variáveis Ordinais são variáveis qualitativas cujas categorias \textbf{possuem uma ordem} ou hierarquia clara e significativa. Podemos classificar os valores do "menor" para o "maior" ou do "pior" para o "melhor".

Exemplos:
\begin{itemize}
	\item \textbf{Avaliação de Satisfação:} A resposta a uma pesquisa (ex: "Muito Insatisfeito", "Insatisfeito", "Neutro", "Satisfeito", "Muito Satisfeito"). Há uma progressão clara de sentimento.
	\item \textbf{Gravidade de um Bug:} A classificação de um erro em um software (ex: "Baixa", "Média", "Alta", "Crítica").
	\item \textbf{Tamanho de Roupa:} "P", "M", "G", "GG". Existe uma ordem de tamanho evidente.
	\item \textbf{Nível de Senioridade:} A classificação de um profissional (ex: "Júnior", "Pleno", "Sênior", "Especialista").
\end{itemize}

\textbf{Contexto em ML/Python/R:} Como existe uma ordem, às vezes não usamos One-Hot Encoding. Em vez disso, podemos usar o \textbf{Label Encoding}, mas com cuidado, mapeando as categorias para números que preservem a ordem (ex: "Baixa" = 1, "Média" = 2, "Alta" = 3). Isso informa ao modelo que "Alta" é mais grave que "Média".

Distinguir entre nominal e ordinal é crucial porque define o tipo de análise descritiva correta (ex: não faz sentido calcular a "média" de uma variável nominal) e a técnica de pré-processamento (encoding) adequada para modelos de Machine Learning.


\subsubsection{Variáveis Quantitativas (Numéricas)}

As \textbf{Variáveis Quantitativas (Numéricas)} são as variáveis que representam "quantidades" ou "números". Elas nos dizem "quanto" ou "quantos". A distinção mais importante é entre \textbf{discretas} e \textbf{contínuas}.\\

\textbf{Variáveis Discretas}

São variáveis numéricas que resultam de uma \textbf{contagem}. Os valores são "contáveis", geralmente números inteiros, e há "saltos" entre os valores possíveis (você pode ter 2 cliques, ou 3, mas não 2,5).

Exemplos :
\begin{itemize}
	\item  \textbf{Itens no Carrinho:} A quantidade de produtos que um cliente tem em um carrinho de compras online (ex: 1, 2, 3... 10 itens).
	\item \textbf{Cliques em um Anúncio:} O número de vezes que um anúncio foi clicado.
	\item \textbf{Erros por Commit:} O número de bugs ou falhas de build introduzidos em um commit de código.
	\item \textbf{Palavras em uma Frase:} O número de palavras em uma avaliação de produto (um exemplo de feature em NLP).
\end{itemize}

Essas variáveis são exatamente o que modelamos com as distribuições \textbf{Binomial} (ex: número de cliques em $n$ visualizações) e \textbf{Poisson} (ex: número de cliques por hora).\\


\textbf{Variáveis Contínuas}

São variáveis numéricas que resultam de uma \textbf{medição}. Elas podem assumir qualquer valor dentro de um intervalo, e a precisão é limitada apenas pelo instrumento de medição.

Exemplos :
\begin{itemize}
	\item \textbf{Tempo de Carregamento:} O tempo (em segundos ou milissegundos) que uma página web leva para carregar (ex: 1.345 segundos).
	\item \textbf{Temperatura de um Servidor:} A temperatura exata de uma CPU (ex: 72.4°C).
	\item \textbf{Valor da Transação:} O valor exato de uma compra (ex: R\$ 119,97). Embora o dinheiro seja tecnicamente discreto (limitado aos centavos), na prática, ele é tratado como contínuo na maioria das modelagens estatísticas.
	\item \textbf{Percentual de Uso de Memória:} O uso de RAM de um serviço (ex: 43,8\%).
\end{itemize}

Essas variáveis são modeladas pelas distribuições \textbf{Normal} (ex: a altura ou peso das pessoas), \textbf{Exponencial} (ex: o tempo até a próxima falha) e \textbf{Uniforme} (ex: gerar um número aleatório para uma simulação).

Distinguir entre discreto e contínuo é o primeiro passo para escolher o modelo de probabilidade correto para seus dados.


\subsection{A Ponte para a Probabilidade: Variável Aleatória (v.a.)}

O conceito de \textbf{Variável Aleatória (v.a.)} é a "ponte" que nos permite sair do mundo dos eventos e entrar no mundo da modelagem matemática. A v.a. é a "tradutora" que pega um resultado do mundo real e atribui um número a ele.\\

\textbf{Nível de Satisfação do Cliente (Tradução Qualitativa Ordinal)}

\begin{itemize}
	\item \textbf{O Experimento:} Um cliente preenche uma pesquisa de satisfação após um atendimento.
	
	\item \textbf{Os Resultados (Qualitativos):} As opções são textuais: "Ruim", "Regular", "Bom", "Ótimo".
	
	\item \textbf{A "Tradução" (v.a. $S$):} Nós criamos uma variável aleatória $S$ que mapeia essas categorias para números que preservam a ordem:
	\subitem Se o resultado for "Ruim", $S = 1$.
	\subitem Se o resultado for "Regular", $S = 2$.
	\subitem Se o resultado for "Bom", $S = 3$.
	\subitem Se o resultado for "Ótimo", $S = 4$.
	
	\item \textbf{O Novo Foco:} Agora podemos fazer perguntas matemáticas:
	\subitem Qual é a probabilidade de $S$ ser 4? ( $P(S=4)$? )
	\subitem Qual é a probabilidade de o atendimento ser "Regular" ou pior? ( $P(S \le 2)$? )
	\subitem Qual é a "média teórica" (Esperança) de satisfação? ( $E(S)$? )\\
\end{itemize}


\textbf{Detecção de Fraude em Transação (Tradução Qualitativa Nominal)}

\begin{itemize}
	\item \textbf{O Experimento:} Um sistema de Machine Learning analisa uma transação de cartão de crédito.
	\item \textbf{Os Resultados (Qualitativos):} O sistema classifica a transação como "Genuína" ou "Fraudulenta".
	
	\item \textbf{A "Tradução" (v.a. $F$):} Criamos uma v.a. binária $F$:
	\subitem Se o resultado for "Genuína", $F = 0$.
	\subitem Se o resultado for "Fraudulenta", $F = 1$.
	
	\item \textbf{O Novo Foco:} Transformamos um problema de classificação em um problema de probabilidade.
	\subitem Qual é a probabilidade de uma transação ser fraude? ( $p = P(F=1)$? )
	\subitem Este é um exemplo perfeito de um experimento de \textbf{Bernoulli}. Se tivermos 100 transações, o número de fraudes seguirá uma \textbf{Binomial}.\\
\end{itemize}


\textbf{Tempo de Resposta de um Servidor (Tradução Contínua)}

\begin{itemize}
	\item \textbf{O Experimento:} Fazemos uma requisição (um ping) a um servidor web.
	\item \textbf{Os Resultados:} O servidor leva um certo tempo para responder.
	
	\item \textbf{A "Tradução" (v.a. $T$):} A v.a. $T$ é o próprio tempo de resposta, medido em milissegundos (ms):
	\subitem Ex: $T = 45.82\text{ ms}$.
	
	\item \textbf{O Novo Foco:} $T$ é uma \textbf{v.a. Contínua}. Não perguntamos "qual a chance de $T$ ser exatamente 45.82ms?" (essa chance é zero), mas sim:
	\subitem Qual é a probabilidade do tempo de resposta ser menor que 100ms? ( $P(T < 100)$? )
	\subitem Qual é a probabilidade de estar entre 40ms e 60ms? ( $P(40 \le T \le 60)$? )
	\subitem Isso seria modelado por uma distribuição contínua, como a \textbf{Exponencial} (tempo até um evento) ou a \textbf{Normal} (se for a média de vários pings).
\end{itemize}

Em todos os casos, a variável aleatória nos permitiu pegar um fenômeno (satisfação, fraude, tempo) e convertê-lo em um número ($S$, $F$, $T$) para o qual podemos definir uma \textbf{função de distribuição de probabilidade}.

\subsection{Por que o Planejamento é Crucial para IA e ML?}

No ecossistema de Inteligência Artificial e Machine Learning, muitas vezes há uma obsessão com a etapa de \textbf{análise de dados} (o algoritmo, o `model.fit()`, a otimização de hiperparâmetros), enquanto as etapas anteriores de planejamento são negligenciadas ou até ignoradas.

O artigo "Is there a role for statistics in artificial intelligence?" é direto: focar apenas na análise é o que leva a "problemas críticos e interpretações possivelmente enganosas". Vamos detalhar por que isso acontece.


\subsubsection{O Problema do "Viés" (Bias)}

Se a coleta de dados cuidadosa não for considerada, correlações espúrias e viés podem falsificar as conclusões. O planejamento é a etapa que define essa "coleta cuidadosa".

Quando o planejamento falha, introduzimos viés (bias). Por exemplo:

\begin{itemize}
	\item \textbf{Viés de Seleção (Amostragem):} Imagine que você quer criar um modelo de ML para prever o risco de crédito de clientes no Brasil. Se você treinar seu modelo apenas com dados de clientes da cidade de São Paulo (uma amostragem de conveniência, não probabilística), o modelo aprenderá padrões específicos daquela região. Ao aplicar esse modelo ao resto do país (a "população"), ele provavelmente falhará miseravelmente. O erro não foi no algoritmo de ML, mas no \textbf{planejamento da amostragem}.
	\item \textbf{Viés de Detecção (Desenho do Estudo):} Se você mede o "sucesso" de um tratamento médico de forma diferente para o grupo de controle e para o grupo experimental (talvez por saber quem tomou o placebo), você introduz um viés que invalida a conclusão.\\
\end{itemize}


\subsubsection{A Armadilha Clássica: O Paradoxo de Simpson}

O \textbf{Paradoxo de Simpson} é um fenômeno estatístico que ocorre quando uma tendência (uma correlação) aparece de forma clara quando olhamos para um grupo de dados de forma agregada (total), mas essa tendência \textbf{desaparece ou se inverte} quando olhamos para os dados divididos em subgrupos.

É uma armadilha clássica porque a conclusão "ingênua" (baseada no total) é o oposto da realidade.\\

\textbf{Exemplo: Análise de Viés de Gênero na Contratação.}

Vamos imaginar que uma empresa de tecnologia quer usar seus dados de contratação para construir um modelo de ML que ajude a "prever o sucesso de um candidato". Antes, ela decide fazer uma auditoria para ver se há viés de gênero em suas contratações atuais.\\

\textit{1. A Análise "Ingênua" (Dados Agregados).}

A empresa analisa os dados de 800 candidatos, 400 homens e 400 mulheres:

\begin{table}[h]
	\centering
	\begin{tabular}{ l c l c l c  l c  l } 
		\hline
		\textbf{Grupo} & \textbf{Candidatos} & \textbf{Contratados} & \textbf{Taxa de Sucesso} \\
		\hline
		Homens & 400 & 185 & 46,25\% \\
		Mulheres & 400 & 90 & 22,5\% \\
		\hline
	\end{tabular}
\end{table}

\textbf{Conclusão (Falsa):} Há um viés chocante \textbf{contra} as mulheres. A taxa de contratação de homens é mais que o dobro da taxa de mulheres. Um modelo de ML treinado com esses dados provavelmente aprenderia que "gênero masculino" é um forte previsor de "ser contratado".\\

\textit{2. O Planejamento e a Variável Oculta.}

Um estatístico  lembra que o \textbf{planejamento do estudo} exige olhar para \textbf{todas} as variáveis relevantes. A variável oculta aqui é o \textbf{Departamento} para o qual eles se candidataram, que têm dificuldades muito diferentes.

Vamos dividir os mesmos 800 candidatos por departamento: "Departamento A" (muito difícil, ex: Engenharia) e "Departamento B" (mais fácil, ex: Vendas).\\


\textit{3. A Realidade (Dados Desagregados)}

Departamento A (Taxa de contratação baixa, ~10\%). Acontece que a maioria das mulheres se candidatou aqui:

\begin{table}[h]
	\centering
	\begin{tabular}{ l c l c l c  l c  l } 
		\hline
		\textbf{Grupo} & \textbf{Candidatos} & \textbf{Contratados} & \textbf{Taxa de Sucesso} \\
		\hline
		Homens & 100 & 8 & 8,0\% \\
		Mulheres & 300 & 30 & 10,0\% \\
		\hline
		Tendência Dept. A: &  &  & Mulheres têm taxa maior
	\end{tabular}
\end{table}

Departamento B (Taxa de contratação alta, ~60\%). Acontece que a maioria dos homens se candidatou aqui:

\begin{table}[h]
	\centering
	\begin{tabular}{ l c l c l c  l c  l } 
		\hline
		\textbf{Grupo} & \textbf{Candidatos} & \textbf{Contratados} & \textbf{Taxa de Sucesso} \\
		\hline
		Homens & 300 & 177 & 59,0\% \\
		Mulheres & 100 & 60 & 60,0\% \\
		\hline
		Tendência Dept. B: &  &  & Mulheres têm taxa maior\\
	\end{tabular}
\end{table}

\textit{4. O Paradoxo}

\begin{itemize}
	\item \textbf{Visão Agregada:} Homens (46,25\%) > Mulheres (22,5\%)
	\item \textbf{Visão Real (Desagregada):} Em \textbf{todos os departamentos}, a taxa de contratação de mulheres é \textbf{maior} que a dos homens.
\end{itemize}

\textbf{A Explicação:} O viés aparente não era de gênero, era de \textbf{distribuição de candidatos}. A maioria das mulheres (300/400) se candidatou ao departamento "difícil", e a maioria dos homens (300/400) se candidatou ao departamento "fácil". O modelo agregado misturou essas duas realidades, criando uma correlação espúria.

Um modelo de IA/ML treinado nos dados agregados teria sido desastroso: ele teria "aprendido" a penalizar mulheres, quando, na verdade, elas tinham um desempenho \textbf{superior} em todos os cenários.